{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1> Data Organizing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./data’: File exists\n",
      "mkdir: cannot create directory ‘./data/train’: File exists\n",
      "mkdir: cannot create directory ‘./data/test’: File exists\n",
      "mkdir: cannot create directory ‘./data/train/images’: File exists\n",
      "mkdir: cannot create directory ‘./data/test/images’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have your test.csv in \"./data/test/test.csv\" and \n",
    "#                     training.csv in \"./data/train/training.csv\"\n",
    "#              train images folder as \"./data/train/images/\"\n",
    "#               test images folder as \"./data/test/images/\"\n",
    "\n",
    "!mkdir ./data\n",
    "!mkdir ./data/train  \n",
    "!mkdir ./data/test\n",
    "!mkdir ./data/train/images  \n",
    "!mkdir ./data/test/images\n",
    "\n",
    "\n",
    "#seperating images of train and test from given Images dataset\n",
    "current_path = !pwd\n",
    "img_dir = os.path.join(current_path[0],'images') #set the path to the actual images dataset folder\n",
    "\n",
    "train_dir = os.path.join(current_path[0],'data','train')\n",
    "train_img_dir = os.path.join(train_dir,'images')\n",
    "train_csv = os.path.join(train_dir,'training.csv')#setting path to Training CSV\n",
    "\n",
    "test_dir = os.path.join(current_path[0],'data','test')\n",
    "test_img_dir = os.path.join(test_dir,'images')\n",
    "test_csv = os.path.join(test_dir,'test.csv')#setting path to Test CSV\n",
    "\n",
    "train = pd.read_csv(train_csv)#Loading Training CSV\n",
    "test  = pd.read_csv(test_csv)# Loading Test CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24000/24000 [47:18<00:00,  8.68it/s] \n",
      "100%|██████████| 24045/24045 [46:52<00:00,  8.57it/s] \n"
     ]
    }
   ],
   "source": [
    "# Moving Images from one destination to other using the names from DataFrame\n",
    "for img in tqdm(train['image_name']):\n",
    "    prev_img = os.path.join(img_dir,img)\n",
    "    img = os.path.join(train_img_dir,img)\n",
    "    !mv $prev_img $img\n",
    "\n",
    "for img in tqdm(test['image_name']):\n",
    "    prev_img = os.path.join(img_dir,img)\n",
    "    img = os.path.join(test_img_dir,img)\n",
    "    !mv $prev_img $img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Got a Image dataset of 14GB. By performing above steps . We filtered 7GB waste data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
